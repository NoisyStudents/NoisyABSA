{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NoisyStudents/NoisyABSA/blob/main/NoisyABSA_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBC_6u6830O1"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import google.colab\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount = True)\n",
        "    IN_COLAB = True\n",
        "except:\n",
        "    IN_COLAB = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtNyXVZS358f"
      },
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "  !pip install transformers==4.28.0\n",
        "  !pip install datasets\n",
        "  !pip install evaluate\n",
        "  !pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZOHrDBeS4HcZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "\n",
        "if IN_COLAB:\n",
        "    root_path = 'Enter colab path'\n",
        "else:\n",
        "    root_path = 'Enter local path'\n",
        "\n",
        "use_mps = True if torch.has_mps else False\n",
        "os.chdir(root_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4R6S56g5PZN"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import pandas as pd\n",
        "\n",
        "from InstructABSA.data_prep import DatasetLoader\n",
        "from InstructABSA.utils import T5Generator\n",
        "from instructions import InstructionsHandler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Nk2-St2C-fD"
      },
      "source": [
        "데이터셋 가져오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zg3ZiBEKC9aE"
      },
      "outputs": [],
      "source": [
        "# for train\n",
        "labeled_dataset = ['preped_Laptop_train.csv']\n",
        "unlabeled_dataset = ['Laptop_unlabeled.csv'] # raw_text 만 존재\n",
        "# for test\n",
        "labeled_to_test = ['preped_Restaurant_trial.csv']\n",
        "# 입력 예시: labeled_dataset = ['a.csv', 'b.csv', 'c.csv']\n",
        "\n",
        "data_path = root_path+'/Dataset/'\n",
        "\n",
        "# 리스트 컴프리헨션을 사용하여 파일들을 읽어와서 concat 수행\n",
        "df_labeled = pd.concat([pd.read_csv(data_path+file) for file in labeled_dataset])\n",
        "df_unlabeled = pd.concat([pd.read_csv(data_path+file) for file in unlabeled_dataset])\n",
        "df_test = pd.concat([pd.read_csv(data_path+file) for file in labeled_to_test])\n",
        "df_unlabeled.rename(columns={'Sentence':'raw_text'}, inplace=True)\n",
        "\n",
        "# df_labeled: DataFrame : raw_text, aspectTerms([{'term': 'cord', 'polarity': 'neutral'}])\n",
        "# df_test: 위와 동일\n",
        "# df_unlabeled : DataFrame: raw_text 만 존재\n",
        "\n",
        "print('df_labeled Form')\n",
        "print(df_labeled.shape)\n",
        "print('df_unlabeled Form')\n",
        "print(df_unlabeled.shape)\n",
        "print('df_test Form')\n",
        "print(df_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9mSs98zC0Nv"
      },
      "source": [
        "##!! Checkpoint 이름 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nysD081OC5EC"
      },
      "outputs": [],
      "source": [
        "task_name = 'joint_task_FinalExperiment'\n",
        "experiment_name = 'CrossDomain_iteration_Rest_Default' # 실험별로 구분할 수 있도록 이름 설정\n",
        "\n",
        "model_checkpoint = 'allenai/tk-instruct-base-def-pos'\n",
        "print('Experiment Name: ', experiment_name)\n",
        "model_out_path = './Models'\n",
        "model_out_path = os.path.join(model_out_path, task_name, f\"{model_checkpoint.replace('/', '')}-{experiment_name}\")\n",
        "print('Model output path: ', model_out_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKgNkZO3ywnX"
      },
      "source": [
        "#### 여기서부터 수행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZGNuVHWMXQZ"
      },
      "outputs": [],
      "source": [
        "def convert_labels_to_aspect_terms(labels):\n",
        "    aspect_terms = []\n",
        "    label_pairs = labels.split(', ')\n",
        "\n",
        "    for pair in label_pairs:\n",
        "        pair_split = pair.split(':')\n",
        "        term = pair_split[0]\n",
        "        polarity = ':'.join(pair_split[1:])\n",
        "        aspect_term = {'term': term, 'polarity': polarity}\n",
        "        aspect_terms.append(aspect_term)\n",
        "\n",
        "    return aspect_terms"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Iteration 1"
      ],
      "metadata": {
        "id": "bYPqChg37p6T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U8hxFnXooA33"
      },
      "outputs": [],
      "source": [
        "use_mps_ = True if torch.has_mps else False\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Get the input text into the required format using Instructions\n",
        "instruct_handler = InstructionsHandler()\n",
        "# Set instruction_set1 for InstructABSA-1 and instruction_set2 for InstructABSA-2\n",
        "instruct_handler.load_instruction_set2()\n",
        "\n",
        "\n",
        "############################################### Vanilla Model ##############################################\n",
        "# Vanilla model 선언\n",
        "t5_exp = T5Generator(model_checkpoint) # tk-instruct\n",
        "\n",
        "# InstructABSA 입력 형태로 전환\n",
        "# Set bos_instruct1 for lapt14 and bos_instruct2 for rest14. For other datasets, modify the insructions.py file.\n",
        "loader = DatasetLoader(df_labeled, df_test)\n",
        "if loader.train_df_id is not None:\n",
        "    loader.train_df_id = loader.create_data_in_joint_task_format(loader.train_df_id, 'term', 'polarity', 'raw_text', 'aspectTerms', instruct_handler.joint['bos_instruct3'], instruct_handler.joint['eos_instruct'])\n",
        "if loader.test_df_id is not None:\n",
        "    loader.test_df_id = loader.create_data_in_joint_task_format(loader.test_df_id, 'term', 'polarity', 'raw_text', 'aspectTerms', instruct_handler.joint['bos_instruct3'], instruct_handler.joint['eos_instruct'])\n",
        "\n",
        "# 뒤에서 사용하기 위해 loader.train_df_id 를 다시 저장해놓기\n",
        "train_data_save = loader.train_df_id.copy()\n",
        "\n",
        "# Tokenize Dataset\n",
        "id_ds, id_tokenized_ds, ood_ds, ood_tokenized_ds = loader.set_data_for_training_semeval(t5_exp.tokenize_function_inputs)\n",
        "\n",
        "# 모델의 매개변수를 디바이스로 이동\n",
        "t5_exp.model = t5_exp.model.to(device)\n",
        "\n",
        "# Vanilla model 성능 평가\n",
        "# Get prediction labels - Training set\n",
        "id_tr_pred_labels = t5_exp.get_labels(tokenized_dataset = id_tokenized_ds, sample_set = 'train', batch_size = 16)\n",
        "id_tr_labels = [i.strip() for i in id_ds['train']['labels']]\n",
        "# Get prediction labels - Testing set\n",
        "id_te_pred_labels = t5_exp.get_labels(tokenized_dataset = id_tokenized_ds, sample_set = 'test', batch_size = 16)\n",
        "id_te_labels = [i.strip() for i in id_ds['test']['labels']]\n",
        "\n",
        "print('First iteration train, test metrics for Vanilla model')\n",
        "print('when equal terms')\n",
        "p, r, f1, _ = t5_exp.get_metrics_eq(id_tr_labels, id_tr_pred_labels)\n",
        "print('Train Precision: ', p)\n",
        "print('Train Recall: ', r)\n",
        "print('Train F1: ', f1)\n",
        "p, r, f1, _ = t5_exp.get_metrics_eq(id_te_labels, id_te_pred_labels)\n",
        "print('Test Precision: ', p)\n",
        "print('Test Recall: ', r)\n",
        "print('Test F1: ', f1)\n",
        "\n",
        "print(' ')\n",
        "print('when include terms')\n",
        "p, r, f1, _ = t5_exp.get_metrics_in(id_tr_labels, id_tr_pred_labels)\n",
        "print('Train Precision: ', p)\n",
        "print('Train Recall: ', r)\n",
        "print('Train F1: ', f1)\n",
        "p, r, f1, _ = t5_exp.get_metrics_in(id_te_labels, id_te_pred_labels)\n",
        "print('Test Precision: ', p)\n",
        "print('Test Recall: ', r)\n",
        "print('Test F1: ', f1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-vUpBSaXiFR"
      },
      "outputs": [],
      "source": [
        "\n",
        "############################################### Teacher Model ##############################################\n",
        "\n",
        "# 첫번째 iteration, teacher model의 checkpoint 명 지정\n",
        "model_out_path = os.path.join(model_out_path, 'joint_task', f\"{model_checkpoint.replace('/', '')}-first_training\")\n",
        "print('First Trained Model output path: ', model_out_path)\n",
        "\n",
        "# Training arguments\n",
        "training_args = {\n",
        "  'output_dir':model_out_path,\n",
        "  'evaluation_strategy':\"epoch\",\n",
        "  'learning_rate':5e-5,\n",
        "  'lr_scheduler_type':'cosine',\n",
        "  'per_device_train_batch_size':8,\n",
        "  'per_device_eval_batch_size':16,\n",
        "  'num_train_epochs':4,\n",
        "  'weight_decay':0.01,\n",
        "  'warmup_ratio':0.1,\n",
        "  'save_strategy':'no',\n",
        "  'load_best_model_at_end':False,\n",
        "  'push_to_hub':False,\n",
        "  'eval_accumulation_steps':1,\n",
        "  'predict_with_generate':True,\n",
        "  'use_mps_device':use_mps_\n",
        "}\n",
        "\n",
        "# teacher model 학습 -> 학습된 모델은 위 model_out_path에 저장\n",
        "t5_trainer = t5_exp.train(id_tokenized_ds, **training_args)\n",
        "\n",
        "# teacher inference\n",
        "# teacher model 선언\n",
        "t5_teacher = T5Generator(model_out_path)\n",
        "id_ds, id_tokenized_ds, ood_ds, ood_tokenized_ds = loader.set_data_for_training_semeval(t5_teacher.tokenize_function_inputs)\n",
        "\n",
        "# 모델의 매개변수를 디바이스로 이동\n",
        "t5_teacher.model = t5_teacher.model.to(device)\n",
        "\n",
        "# inference train, test dataset\n",
        "# Get prediction labels - Training set\n",
        "id_tr_pred_labels = t5_teacher.get_labels(tokenized_dataset = id_tokenized_ds, sample_set = 'train', batch_size = 16)\n",
        "id_tr_labels = [i.strip() for i in id_ds['train']['labels']]\n",
        "# Get prediction labels - Testing set\n",
        "id_te_pred_labels = t5_teacher.get_labels(tokenized_dataset = id_tokenized_ds, sample_set = 'test', batch_size = 16)\n",
        "id_te_labels = [i.strip() for i in id_ds['test']['labels']]\n",
        "\n",
        "print('First iteration train, test metrics for teacher model')\n",
        "print('when equal terms')\n",
        "p, r, f1, _ = t5_teacher.get_metrics_eq(id_tr_labels, id_tr_pred_labels)\n",
        "print('Train Precision: ', p)\n",
        "print('Train Recall: ', r)\n",
        "print('Train F1: ', f1)\n",
        "p, r, f1, _ = t5_teacher.get_metrics_eq(id_te_labels, id_te_pred_labels)\n",
        "print('Test Precision: ', p)\n",
        "print('Test Recall: ', r)\n",
        "print('Test F1: ', f1)\n",
        "\n",
        "print(' ')\n",
        "print('when include terms')\n",
        "p, r, f1, _ = t5_teacher.get_metrics_in(id_tr_labels, id_tr_pred_labels)\n",
        "print('Train Precision: ', p)\n",
        "print('Train Recall: ', r)\n",
        "print('Train F1: ', f1)\n",
        "p, r, f1, _ = t5_teacher.get_metrics_in(id_te_labels, id_te_pred_labels)\n",
        "print('Test Precision: ', p)\n",
        "print('Test Recall: ', r)\n",
        "print('Test F1: ', f1)\n",
        "\n",
        "\n",
        "# 학습된 teacher 모델을 이용해 unlabeled dataset에 대한 inference 수행\n",
        "#inference unlabeled dataset\n",
        "tokenizer = t5_teacher.tokenizer\n",
        "model = t5_teacher.model\n",
        "\n",
        "# InstructABSA 입력 형태와 동일하게\n",
        "df_unlabeled_inferenced = pd.DataFrame()\n",
        "df_unlabeled_inferenced['raw_text'] = df_unlabeled['raw_text']\n",
        "df_unlabeled_inferenced['text'] = input_text = instruct_handler.joint['bos_instruct3'] + df_unlabeled_inferenced['raw_text'] + '' + instruct_handler.joint['eos_instruct']\n",
        "output_list = []\n",
        "for text in df_unlabeled_inferenced['text']:\n",
        "    tokenized_text = tokenizer(text,return_tensors=\"pt\")\n",
        "    tokenized_text.to(device)\n",
        "    output = tokenizer.decode(model.generate(tokenized_text.input_ids)[0].to(device), skip_special_tokens=True)\n",
        "    output_list.append(output)\n",
        "df_unlabeled_inferenced['labels'] = output_list\n",
        "df_unlabeled_inferenced['aspectTerms'] = df_unlabeled_inferenced['labels'].apply(convert_labels_to_aspect_terms)\n",
        "df_unlabeled_inferenced['Unnamed: 0'] = df_unlabeled_inferenced.index\n",
        "\n",
        "############################################### Student Model 1 ##############################################\n",
        "# student training\n",
        "# student trainig을 위해 df_labeled 와 df_unlabeled_inferenced를 concat하여 training_df 형성\n",
        "loader.train_df_id = pd.concat([train_data_save, df_unlabeled_inferenced])\n",
        "\n",
        "# student baseline 선언\n",
        "t5_exp = T5Generator(model_checkpoint) # tk-instruct\n",
        "\n",
        "# Tokenize Dataset\n",
        "id_ds, id_tokenized_ds, ood_ds, ood_tokenized_ds = loader.set_data_for_training_semeval(t5_exp.tokenize_function_inputs)\n",
        "\n",
        "# 모델의 매개변수를 디바이스로 이동\n",
        "t5_exp.model = t5_exp.model.to(device)\n",
        "\n",
        "model_out_path = os.path.join(model_out_path, 'joint_task', f\"{model_checkpoint.replace('/', '')}-second_training\")\n",
        "print('Model output path: ', model_out_path)\n",
        "\n",
        "# Training arguments\n",
        "training_args = {\n",
        "  'output_dir':model_out_path,\n",
        "  'evaluation_strategy':\"epoch\",\n",
        "  'learning_rate':5e-5,\n",
        "  'lr_scheduler_type':'cosine',\n",
        "  'per_device_train_batch_size':8,\n",
        "  'per_device_eval_batch_size':16,\n",
        "  'num_train_epochs':4,\n",
        "  'weight_decay':0.01,\n",
        "  'warmup_ratio':0.1,\n",
        "  'save_strategy':'no',\n",
        "  'load_best_model_at_end':False,\n",
        "  'push_to_hub':False,\n",
        "  'eval_accumulation_steps':1,\n",
        "  'predict_with_generate':True,\n",
        "  'use_mps_device':use_mps_\n",
        "}\n",
        "\n",
        "# student model 학습\n",
        "t5_trainer = t5_exp.train(id_tokenized_ds, **training_args)\n",
        "\n",
        "# student inference\n",
        "t5_student = T5Generator(model_out_path)\n",
        "id_ds, id_tokenized_ds, ood_ds, ood_tokenized_ds = loader.set_data_for_training_semeval(t5_student.tokenize_function_inputs)\n",
        "\n",
        "\n",
        "# 모델의 매개변수를 디바이스로 이동\n",
        "t5_student.model = t5_student.model.to(device)\n",
        "\n",
        "# inference train, test dataset\n",
        "# Get prediction labels - Training set\n",
        "\n",
        "id_tr_pred_labels = t5_student.get_labels(tokenized_dataset = id_tokenized_ds, sample_set = 'train', batch_size = 16)\n",
        "id_tr_labels = [i.strip() for i in id_ds['train']['labels']]\n",
        "# Get prediction labels - Testing set\n",
        "id_te_pred_labels = t5_student.get_labels(tokenized_dataset = id_tokenized_ds, sample_set = 'test', batch_size = 16)\n",
        "id_te_labels = [i.strip() for i in id_ds['test']['labels']]\n",
        "\n",
        "print('First iteration train, test metrics for student model')\n",
        "print('when equal terms')\n",
        "p, r, f1, _ = t5_student.get_metrics_eq(id_tr_labels, id_tr_pred_labels)\n",
        "print('Train Precision: ', p)\n",
        "print('Train Recall: ', r)\n",
        "print('Train F1: ', f1)\n",
        "p, r, f1, _ = t5_student.get_metrics_eq(id_te_labels, id_te_pred_labels)\n",
        "print('Test Precision: ', p)\n",
        "print('Test Recall: ', r)\n",
        "print('Test F1: ', f1)\n",
        "\n",
        "print(' ')\n",
        "print('when include terms')\n",
        "p, r, f1, _ = t5_student.get_metrics_in(id_tr_labels, id_tr_pred_labels)\n",
        "print('Train Precision: ', p)\n",
        "print('Train Recall: ', r)\n",
        "print('Train F1: ', f1)\n",
        "p, r, f1, _ = t5_student.get_metrics_in(id_te_labels, id_te_pred_labels)\n",
        "print('Test Precision: ', p)\n",
        "print('Test Recall: ', r)\n",
        "print('Test F1: ', f1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# student model1의 inference 수행\n",
        "\n",
        "# 학습된 student 모델을 이용해 unlabeled dataset에 대한 inference 수행\n",
        "#inference unlabeled dataset\n",
        "tokenizer = t5_student.tokenizer\n",
        "model = t5_student.model\n",
        "\n",
        "# InstructABSA 입력 형태와 동일하게\n",
        "df_unlabeled_inferenced = pd.DataFrame()\n",
        "df_unlabeled_inferenced['raw_text'] = df_unlabeled['raw_text']\n",
        "df_unlabeled_inferenced['text'] = input_text = instruct_handler.joint['bos_instruct3'] + df_unlabeled_inferenced['raw_text'] + '' + instruct_handler.joint['eos_instruct']\n",
        "output_list = []\n",
        "for text in df_unlabeled_inferenced['text']:\n",
        "    tokenized_text = tokenizer(text,return_tensors=\"pt\")\n",
        "    tokenized_text.to(device)\n",
        "    output = tokenizer.decode(model.generate(tokenized_text.input_ids)[0].to(device), skip_special_tokens=True)\n",
        "    output_list.append(output)\n",
        "df_unlabeled_inferenced['labels'] = output_list\n",
        "df_unlabeled_inferenced['aspectTerms'] = df_unlabeled_inferenced['labels'].apply(convert_labels_to_aspect_terms)\n",
        "df_unlabeled_inferenced['Unnamed: 0'] = df_unlabeled_inferenced.index\n",
        "\n"
      ],
      "metadata": {
        "id": "9Yz-Tj_SHRaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Iteration 2"
      ],
      "metadata": {
        "id": "wjeSVgC57tOe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "############################################### Student Model 2 ##############################################\n",
        "\n",
        "# student2 trainig을 위해 df_labeled 와 student1에서 inference했던 df_unlabeled_inferenced를 concat하여 training_df 형성\n",
        "loader.train_df_id = pd.concat([train_data_save, df_unlabeled_inferenced])\n",
        "\n",
        "# 이때 앞 iteration에서 학습시켰던 student 모델을 가져옴\n",
        "t5_exp = T5Generator(model_out_path) # new teacher baseline 가져오기\n",
        "\n",
        "\n",
        "# Tokenize Dataset\n",
        "id_ds, id_tokenized_ds, ood_ds, ood_tokenized_ds = loader.set_data_for_training_semeval(t5_exp.tokenize_function_inputs)\n",
        "\n",
        "\n",
        "# 모델의 매개변수를 디바이스로 이동\n",
        "t5_exp.model = t5_exp.model.to(device)\n",
        "\n",
        "# 두번째 iteration, teacher model의 checkpoint 명 지정\n",
        "model_out_path = os.path.join(model_out_path, 'joint_task', f\"{model_checkpoint.replace('/', '')}-third_training\")\n",
        "print('Third Trained Model output path: ', model_out_path)\n",
        "\n",
        "\n",
        "# Training arguments\n",
        "training_args = {\n",
        "  'output_dir':model_out_path,\n",
        "  'evaluation_strategy':\"epoch\",\n",
        "  'learning_rate':5e-5,\n",
        "  'lr_scheduler_type':'cosine',\n",
        "  'per_device_train_batch_size':8,\n",
        "  'per_device_eval_batch_size':16,\n",
        "  'num_train_epochs':4,\n",
        "  'weight_decay':0.01,\n",
        "  'warmup_ratio':0.1,\n",
        "  'save_strategy':'no',\n",
        "  'load_best_model_at_end':False,\n",
        "  'push_to_hub':False,\n",
        "  'eval_accumulation_steps':1,\n",
        "  'predict_with_generate':True,\n",
        "  'use_mps_device':use_mps_\n",
        "}\n",
        "\n",
        "# student model 학습\n",
        "t5_trainer = t5_exp.train(id_tokenized_ds, **training_args)\n",
        "\n",
        "# student inference\n",
        "t5_student2 = T5Generator(model_out_path)\n",
        "id_ds, id_tokenized_ds, ood_ds, ood_tokenized_ds = loader.set_data_for_training_semeval(t5_student2.tokenize_function_inputs)\n",
        "\n",
        "\n",
        "# 모델의 매개변수를 디바이스로 이동\n",
        "t5_student2.model = t5_student2.model.to(device)\n",
        "\n",
        "# inference train, test dataset\n",
        "# Get prediction labels - Training set\n",
        "\n",
        "id_tr_pred_labels = t5_student2.get_labels(tokenized_dataset = id_tokenized_ds, sample_set = 'train', batch_size = 16)\n",
        "id_tr_labels = [i.strip() for i in id_ds['train']['labels']]\n",
        "# Get prediction labels - Testing set\n",
        "id_te_pred_labels = t5_student2.get_labels(tokenized_dataset = id_tokenized_ds, sample_set = 'test', batch_size = 16)\n",
        "id_te_labels = [i.strip() for i in id_ds['test']['labels']]\n",
        "\n",
        "print('Second iteration train, test metrics for student model')\n",
        "print('when equal terms')\n",
        "p, r, f1, _ = t5_student2.get_metrics_eq(id_tr_labels, id_tr_pred_labels)\n",
        "print('Train Precision: ', p)\n",
        "print('Train Recall: ', r)\n",
        "print('Train F1: ', f1)\n",
        "p, r, f1, _ = t5_student2.get_metrics_eq(id_te_labels, id_te_pred_labels)\n",
        "print('Test Precision: ', p)\n",
        "print('Test Recall: ', r)\n",
        "print('Test F1: ', f1)\n",
        "\n",
        "print(' ')\n",
        "print('when include terms')\n",
        "p, r, f1, _ = t5_student2.get_metrics_in(id_tr_labels, id_tr_pred_labels)\n",
        "print('Train Precision: ', p)\n",
        "print('Train Recall: ', r)\n",
        "print('Train F1: ', f1)\n",
        "p, r, f1, _ = t5_student2.get_metrics_in(id_te_labels, id_te_pred_labels)\n",
        "print('Test Precision: ', p)\n",
        "print('Test Recall: ', r)\n",
        "print('Test F1: ', f1)\n"
      ],
      "metadata": {
        "id": "cI-7BPGR7yGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# student model2의 inference 수행\n",
        "\n",
        "# 학습된 student 모델을 이용해 unlabeled dataset에 대한 inference 수행\n",
        "#inference unlabeled dataset\n",
        "tokenizer = t5_student2.tokenizer\n",
        "model = t5_student2.model\n",
        "\n",
        "# InstructABSA 입력 형태와 동일하게\n",
        "df_unlabeled_inferenced = pd.DataFrame()\n",
        "df_unlabeled_inferenced['raw_text'] = df_unlabeled['raw_text']\n",
        "df_unlabeled_inferenced['text'] = input_text = instruct_handler.joint['bos_instruct3'] + df_unlabeled_inferenced['raw_text'] + '' + instruct_handler.joint['eos_instruct']\n",
        "output_list = []\n",
        "for text in df_unlabeled_inferenced['text']:\n",
        "    tokenized_text = tokenizer(text,return_tensors=\"pt\")\n",
        "    tokenized_text.to(device)\n",
        "    output = tokenizer.decode(model.generate(tokenized_text.input_ids)[0].to(device), skip_special_tokens=True)\n",
        "    output_list.append(output)\n",
        "df_unlabeled_inferenced['labels'] = output_list\n",
        "df_unlabeled_inferenced['aspectTerms'] = df_unlabeled_inferenced['labels'].apply(convert_labels_to_aspect_terms)\n",
        "df_unlabeled_inferenced['Unnamed: 0'] = df_unlabeled_inferenced.index\n",
        "\n"
      ],
      "metadata": {
        "id": "2ywjA3cfHVY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### iteration 3"
      ],
      "metadata": {
        "id": "VF3-FEBUYtQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "############################################### Student Model 3 ##############################################\n",
        "\n",
        "# student3 trainig을 위해 df_labeled 와 student1에서 inference했던 df_unlabeled_inferenced를 concat하여 training_df 형성\n",
        "loader.train_df_id = pd.concat([train_data_save, df_unlabeled_inferenced])\n",
        "\n",
        "# 이때 앞 iteration에서 학습시켰던 student 모델을 가져옴\n",
        "t5_exp = T5Generator(model_out_path) # new teacher baseline 가져오기\n",
        "\n",
        "\n",
        "# Tokenize Dataset\n",
        "id_ds, id_tokenized_ds, ood_ds, ood_tokenized_ds = loader.set_data_for_training_semeval(t5_exp.tokenize_function_inputs)\n",
        "\n",
        "\n",
        "# 모델의 매개변수를 디바이스로 이동\n",
        "t5_exp.model = t5_exp.model.to(device)\n",
        "\n",
        "# 두번째 iteration, teacher model의 checkpoint 명 지정\n",
        "model_out_path = os.path.join(model_out_path, 'joint_task', f\"{model_checkpoint.replace('/', '')}-fourth_training\")\n",
        "print('Fourth Trained Model output path: ', model_out_path)\n",
        "\n",
        "\n",
        "# Training arguments\n",
        "training_args = {\n",
        "  'output_dir':model_out_path,\n",
        "  'evaluation_strategy':\"epoch\",\n",
        "  'learning_rate':5e-5,\n",
        "  'lr_scheduler_type':'cosine',\n",
        "  'per_device_train_batch_size':8,\n",
        "  'per_device_eval_batch_size':16,\n",
        "  'num_train_epochs':4,\n",
        "  'weight_decay':0.01,\n",
        "  'warmup_ratio':0.1,\n",
        "  'save_strategy':'no',\n",
        "  'load_best_model_at_end':False,\n",
        "  'push_to_hub':False,\n",
        "  'eval_accumulation_steps':1,\n",
        "  'predict_with_generate':True,\n",
        "  'use_mps_device':use_mps_\n",
        "}\n",
        "\n",
        "# student model 학습\n",
        "t5_trainer = t5_exp.train(id_tokenized_ds, **training_args)\n",
        "\n",
        "# student inference\n",
        "t5_student3 = T5Generator(model_out_path)\n",
        "id_ds, id_tokenized_ds, ood_ds, ood_tokenized_ds = loader.set_data_for_training_semeval(t5_student3.tokenize_function_inputs)\n",
        "\n",
        "\n",
        "# 모델의 매개변수를 디바이스로 이동\n",
        "t5_student3.model = t5_student3.model.to(device)\n",
        "\n",
        "# inference train, test dataset\n",
        "# Get prediction labels - Training set\n",
        "\n",
        "id_tr_pred_labels = t5_student3.get_labels(tokenized_dataset = id_tokenized_ds, sample_set = 'train', batch_size = 16)\n",
        "id_tr_labels = [i.strip() for i in id_ds['train']['labels']]\n",
        "# Get prediction labels - Testing set\n",
        "id_te_pred_labels = t5_student3.get_labels(tokenized_dataset = id_tokenized_ds, sample_set = 'test', batch_size = 16)\n",
        "id_te_labels = [i.strip() for i in id_ds['test']['labels']]\n",
        "\n",
        "print('Third iteration train, test metrics for student model')\n",
        "print('when equal terms')\n",
        "p, r, f1, _ = t5_student3.get_metrics_eq(id_tr_labels, id_tr_pred_labels)\n",
        "print('Train Precision: ', p)\n",
        "print('Train Recall: ', r)\n",
        "print('Train F1: ', f1)\n",
        "p, r, f1, _ = t5_student3.get_metrics_eq(id_te_labels, id_te_pred_labels)\n",
        "print('Test Precision: ', p)\n",
        "print('Test Recall: ', r)\n",
        "print('Test F1: ', f1)\n",
        "\n",
        "print(' ')\n",
        "print('when include terms')\n",
        "p, r, f1, _ = t5_student3.get_metrics_in(id_tr_labels, id_tr_pred_labels)\n",
        "print('Train Precision: ', p)\n",
        "print('Train Recall: ', r)\n",
        "print('Train F1: ', f1)\n",
        "p, r, f1, _ = t5_student3.get_metrics_in(id_te_labels, id_te_pred_labels)\n",
        "print('Test Precision: ', p)\n",
        "print('Test Recall: ', r)\n",
        "print('Test F1: ', f1)\n"
      ],
      "metadata": {
        "id": "FBR3cUY0YOvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### iteration 4"
      ],
      "metadata": {
        "id": "NkDdo3j6bUXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# student model3의 inference 수행\n",
        "\n",
        "# 학습된 student 모델을 이용해 unlabeled dataset에 대한 inference 수행\n",
        "#inference unlabeled dataset\n",
        "tokenizer = t5_student3.tokenizer\n",
        "model = t5_student3.model\n",
        "\n",
        "# InstructABSA 입력 형태와 동일하게\n",
        "df_unlabeled_inferenced = pd.DataFrame()\n",
        "df_unlabeled_inferenced['raw_text'] = df_unlabeled['raw_text']\n",
        "df_unlabeled_inferenced['text'] = input_text = instruct_handler.joint['bos_instruct3'] + df_unlabeled_inferenced['raw_text'] + '' + instruct_handler.joint['eos_instruct']\n",
        "output_list = []\n",
        "for text in df_unlabeled_inferenced['text']:\n",
        "    tokenized_text = tokenizer(text,return_tensors=\"pt\")\n",
        "    tokenized_text.to(device)\n",
        "    output = tokenizer.decode(model.generate(tokenized_text.input_ids)[0].to(device), skip_special_tokens=True)\n",
        "    output_list.append(output)\n",
        "df_unlabeled_inferenced['labels'] = output_list\n",
        "df_unlabeled_inferenced['aspectTerms'] = df_unlabeled_inferenced['labels'].apply(convert_labels_to_aspect_terms)\n",
        "df_unlabeled_inferenced['Unnamed: 0'] = df_unlabeled_inferenced.index\n",
        "\n"
      ],
      "metadata": {
        "id": "xWvgPOiBbT-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############################################### Student Model 4 ##############################################\n",
        "\n",
        "# student4 trainig을 위해 df_labeled 와 student1에서 inference했던 df_unlabeled_inferenced를 concat하여 training_df 형성\n",
        "loader.train_df_id = pd.concat([train_data_save, df_unlabeled_inferenced])\n",
        "\n",
        "# 이때 앞 iteration에서 학습시켰던 student 모델을 가져옴\n",
        "t5_exp = T5Generator(model_out_path) # new teacher baseline 가져오기\n",
        "\n",
        "\n",
        "# Tokenize Dataset\n",
        "id_ds, id_tokenized_ds, ood_ds, ood_tokenized_ds = loader.set_data_for_training_semeval(t5_exp.tokenize_function_inputs)\n",
        "\n",
        "\n",
        "# 모델의 매개변수를 디바이스로 이동\n",
        "t5_exp.model = t5_exp.model.to(device)\n",
        "\n",
        "# 두번째 iteration, teacher model의 checkpoint 명 지정\n",
        "model_out_path = os.path.join(model_out_path, 'joint_task', f\"{model_checkpoint.replace('/', '')}-fifth_training\")\n",
        "print('Fifth Trained Model output path: ', model_out_path)\n",
        "\n",
        "\n",
        "# Training arguments\n",
        "training_args = {\n",
        "  'output_dir':model_out_path,\n",
        "  'evaluation_strategy':\"epoch\",\n",
        "  'learning_rate':5e-5,\n",
        "  'lr_scheduler_type':'cosine',\n",
        "  'per_device_train_batch_size':8,\n",
        "  'per_device_eval_batch_size':16,\n",
        "  'num_train_epochs':4,\n",
        "  'weight_decay':0.01,\n",
        "  'warmup_ratio':0.1,\n",
        "  'save_strategy':'no',\n",
        "  'load_best_model_at_end':False,\n",
        "  'push_to_hub':False,\n",
        "  'eval_accumulation_steps':1,\n",
        "  'predict_with_generate':True,\n",
        "  'use_mps_device':use_mps_\n",
        "}\n",
        "\n",
        "# student model 학습\n",
        "t5_trainer = t5_exp.train(id_tokenized_ds, **training_args)\n",
        "\n",
        "# student inference\n",
        "t5_student4 = T5Generator(model_out_path)\n",
        "id_ds, id_tokenized_ds, ood_ds, ood_tokenized_ds = loader.set_data_for_training_semeval(t5_student4.tokenize_function_inputs)\n",
        "\n",
        "\n",
        "# 모델의 매개변수를 디바이스로 이동\n",
        "t5_student4.model = t5_student4.model.to(device)\n",
        "\n",
        "# inference train, test dataset\n",
        "# Get prediction labels - Training set\n",
        "\n",
        "id_tr_pred_labels = t5_student4.get_labels(tokenized_dataset = id_tokenized_ds, sample_set = 'train', batch_size = 16)\n",
        "id_tr_labels = [i.strip() for i in id_ds['train']['labels']]\n",
        "# Get prediction labels - Testing set\n",
        "id_te_pred_labels = t5_student4.get_labels(tokenized_dataset = id_tokenized_ds, sample_set = 'test', batch_size = 16)\n",
        "id_te_labels = [i.strip() for i in id_ds['test']['labels']]\n",
        "\n",
        "print('Fourth iteration train, test metrics for student model')\n",
        "print('when equal terms')\n",
        "p, r, f1, _ = t5_student4.get_metrics_eq(id_tr_labels, id_tr_pred_labels)\n",
        "print('Train Precision: ', p)\n",
        "print('Train Recall: ', r)\n",
        "print('Train F1: ', f1)\n",
        "p, r, f1, _ = t5_student4.get_metrics_eq(id_te_labels, id_te_pred_labels)\n",
        "print('Test Precision: ', p)\n",
        "print('Test Recall: ', r)\n",
        "print('Test F1: ', f1)\n",
        "\n",
        "print(' ')\n",
        "print('when include terms')\n",
        "p, r, f1, _ = t5_student4.get_metrics_in(id_tr_labels, id_tr_pred_labels)\n",
        "print('Train Precision: ', p)\n",
        "print('Train Recall: ', r)\n",
        "print('Train F1: ', f1)\n",
        "p, r, f1, _ = t5_student4.get_metrics_in(id_te_labels, id_te_pred_labels)\n",
        "print('Test Precision: ', p)\n",
        "print('Test Recall: ', r)\n",
        "print('Test F1: ', f1)\n"
      ],
      "metadata": {
        "id": "dUw2CS_Obkd8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}